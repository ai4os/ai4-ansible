# Increase log verbosity
#log_level = "DEBUG"
 
# Make sure Nomad nodes leave before shutting down the agent to prevent messing up the raft consensus
leave_on_interrupt = true
leave_on_terminate = true
 
# Enable the client
client {
  enabled = true

  options {
    "docker.cleanup.image" = "false"
    "docker.cleanup.image.delay" = "120d"  
    "fingerprint.denylist" = "env_aws,env_gce,env_azure,env_digitalocean"  
  }

  meta {
  
   # list of namespaces supported by each client (those specificed in the hosts file)
   namespace = "{{ nomad_namespaces }}"

{% if ("traefik_master" in groups and inventory_hostname in groups['traefik_master']) or ("traefik_new_master" in groups and inventory_hostname in groups['traefik_new_master'])%}
   # Traefik tags needed for both functionalities: traefik_master in from-scratch deployment and traefik_new_master in joining cluster
   type = "traefik"
{% elif ("nomad_tryme_clients" in groups and inventory_hostname in groups['nomad_tryme_clients']) or ("new_nomad_tryme_clients" in groups and inventory_hostname in groups['new_nomad_tryme_clients'])%}
   # rest of Nomad clients tags needed for both functionalities: in nodes that are not traefik_master nor traefik_new_master
   type = "tryme"
{% elif (batch|default(false) == "true")%}
  type = "batch"
{% else %}
  type = "compute"
{% endif %}

{% if ("nomad_gpu_clients" in groups and inventory_hostname in groups["nomad_gpu_clients"]) or ("nomad_new_gpu_clients" in groups and inventory_hostname in groups["nomad_new_gpu_clients"]) %}
  # GPU tag for both functionalities: nomad_gpu_clients in from-scratch deployment and nomad_new_gpu_clients in joining cluster
tags = "gpu"
{% else %}
  # CPU tag for both functionalities: rest of Nomad clients (not Traefik nor GPU)
tags = "cpu"
{% endif %}

   # Nomad client's domain (specified in the hosts file)
   domain = "{{ domain }}"
   ansible_version = "{{ commit_id_fact }}"
{% for key, value in nomad_client_meta.items() %}
   {{ key }} = "{{ value }}"
{% endfor %}

  }

{% if ("traefik_master" not in groups or inventory_hostname not in groups['traefik_master']) and ("traefik_new_master" not in groups or inventory_hostname not in groups['traefik_new_master']) %}
  # Reserve memory in compute Nomad clients (those that are not Traefik nodes: traefik_master or new_traefik_master)
  reserved = {
   memory = {{ nomad_reserved_memory_mb }}
  }
{% endif %}
}
  # For demo assume you are talking to server1. For production,
  # this should be like "nomad.service.consul:4647" and a system
  # like Consul used for service discovery.
 
# Modify our port to avoid a collision with server1
 
# Require TLS
tls {
  http = true
  rpc  = true
 
  ca_file   = "{{ nomad_certs }}nomad-ca.pem"
  cert_file = "{{ nomad_certs }}client.pem"
  key_file  = "{{ nomad_certs }}client-key.pem"
 
  verify_server_hostname = true
  verify_https_client    = true
}
 
# Bind to all addresses so that the Nomad agent is available both on loopback
# and externally.
bind_addr = "0.0.0.0"
 
# Advertise an accessible IP address so the server is reachable by other servers
# and clients. The IPs can be materialized by Terraform or be replaced by an
# init script.
advertise {
    http = "{{ ansible_host }}:4646"
    rpc = "{{ ansible_host }}:4647"
    serf = "{{ ansible_host }}:4648"
}
 
consul {
    # The address to the Consul agent.
    address = "127.0.0.1:8500"

    # token is first set to default and then changed to each agent's token
    token = "{{ agent_nomad_token }}"
 
    # The service name to register the server and client with Consul.
    server_service_name = "nomad-server"
    client_service_name = "nomad-client"
 
    # Enables automatically registering the services.
    auto_advertise = true
 
    # Enabling the server and client to bootstrap using Consul.
    server_auto_join = true
    client_auto_join = true
}
 
plugin "docker" {
  config {
    gc {
      image       = false
      image_delay = "3m"
    }
    allow_privileged = true
    volumes {
      enabled = true
    }
    image_pull_timeout = "30m"
  }
}
 
#this will be later removed from production datacenters
plugin "raw_exec" {
  config {
    enabled = true
  }
}

{% if ("nomad_gpu_clients" in groups and inventory_hostname in groups["nomad_gpu_clients"]) or ("nomad_new_gpu_clients" in groups and inventory_hostname in groups["nomad_new_gpu_clients"]) %}
plugin "nomad-device-nvidia" {
  config {
    enabled            = true
    fingerprint_period = "1m"
  }
}
{% endif %}